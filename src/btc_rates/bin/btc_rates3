#!/usr/bin/env python3
# -*- coding: utf-8 -*-
# btc_rates3 - Thursday, November 14, 2024
# Ref: http://bit.ly/2qZwqkp
# http://blockxchain.org/2017/06/03/blockchain-and-python-exploring-the-python-blockchain-package/
""" Retrieve Bitcoin prices using the blockchain library """
__version__ = "3.1.1-dev4"

import os
import sys
from datetime import datetime, timedelta, timezone
from pathlib import Path
from time import sleep

import sqlalchemy as sa
import xdg
from blockchain import exchangerates as er
# from blockchain import statistics as st
from environs import Env
from loguru import logger
from sqlalchemy import create_engine, text
# from xdg import XDG_CACHE_HOME, XDG_CONFIG_HOME, XDG_DATA_HOME, XDG_RUNTIME_DIR

_basedir = Path(__file__).resolve().parent.parent
__org__ = "LevellTech"
__project__ = _basedir.stem
__module__ = Path(__file__).resolve().stem

env = Env(expand_vars=True)
env.read_env()


# This is the main function
def get_prices():
	# fn_logger = logging.getLogger(__module__ + ".get_prices")
	dt = datetime.now().astimezone()
	rate_cad = rate_usd = None
	retries = 3
	while retries > 0:
		retries -= 1
		try:
			dt = datetime.now().astimezone()
			rates = er.get_ticker()
			rate_cad = rates["CAD"]
			rate_usd = rates["USD"]
			retries = -1
		except er.util.TIMEOUT as e:
			logger.exception("TIMEOUT: %s  Retries: %d" % (e, retries))
		except er.util.HTTPError as e:
			logger.exception("HTTP Error: %s  Retries: %d" % (e, retries))
		except er.util.APIException as e:
			logger.exception("API Exception: %s  Retries: %d" % (e, retries))
		except Exception as e:
			logger.exception("Exception: %s  Retries: %d" % (e, retries))
	cad_price = f"{rate_cad.symbol} {rate_cad.p15min:,.2f}"
	usd_price = f"{rate_usd.symbol} {rate_usd.p15min:,.2f}"
	logger.info(f"{cad_price}\t{usd_price}")
	columns = "date_id date_time cad usd".split()
	cols = ",".join(columns)
	placeholders = ",".join([f":{x}" for x in columns])
	sql = "\n".join([
		f"INSERT INTO dt_price({cols}) VALUES",
		f"({placeholders});"
	])
	params = {
		"date_id": dt.date(),
		"date_time": dt,
		"cad": float(rate_cad.p15min),
		"usd": float(rate_usd.p15min),
	}
	with engine.connect() as conn:
		result = conn.execute(text(sql), params)
		if result.rowcount < 0:
			logger.warning("This was unexpected")
		conn.commit()
	return


def init():
	print(f"Organization  . . {__org__}")
	print(f"Project . . . . . {__project__}")
	print(f"Module  . . . . . {__module__}")
	print(f"Base Dir  . . . . {_basedir}")
	print(f"Cache Dir . . . . {_cache_dir}")
	print(f"Config Dir  . . . {_config_dir}")
	print(f"Data Dir  . . . . {_data_dir}")
	print(f"Log Dir . . . . . {_log_dir}")
	print(f"Runtime Dir . . . {_runtime_dir}")
	return


def eoj():

	return


"""
logger.info(_run_dt.replace(microsecond=0).isoformat(), "\t",
	"CAD", rate_cad.symbol, format(rate_cad.p15min, ",.2f"), "\t",
	"USD", rate_usd.symbol, format(rate_usd.p15min, ",.2f"))
"""
"""
Response object field definitions

Currency

last : float
buy : float
sell : float
symbol : str
p15min : float - 15 minute delayed price
"""


if __name__ == "__main__":
	_run_dt = datetime.now().astimezone().replace(microsecond=0)
	_run_utc = _run_dt.astimezone(timezone.utc).replace(tzinfo=None)
	_fdate = _run_dt.strftime("%Y-%m")

	# Directories
	_cache_dir = xdg.xdg_cache_home() / __org__ / __project__
	_config_dir = xdg.xdg_config_home() / __org__ / __project__
	_data_dir = xdg.xdg_data_home() / __org__ / __project__
	_runtime_dir = xdg.xdg_runtime_dir() / __org__ / __project__
	_state_dir = xdg.xdg_state_home() / __org__ / __project__
	# Sub-Directories
	_log_dir = _state_dir / "log"

	# Environment
	env_file = _config_dir / "environment"
	print(env_file)
	if env_file.exists():
		env.read_env(env_file, override=True, recurse=True)
	_debug = env.bool("DEBUG", default=False)

	# Configure Logging (using Loguru)
	_logfile = _log_dir / f"{__module__}_{_fdate}.log"
	_errfile = _log_dir / f"{__module__}.err"

	logger.remove(0)
	logger.add(
		sys.stderr,
		backtrace=True,
		colorize=True,
		diagnose=True,
		format="<level>{level:8s} {function}:{line:03d}  {message}</level>",
		level=0,
	)
	logger.add(
		_logfile,
		colorize=False,
		compression="gz",
		format="<green>{time:%Y-%m-%d %H:%M:%S%z}</green> <level>{level:8s} {name}:{function}:{line:03d}  {message}</level>",
		rotation="10 MB",
		level="TRACE",
	)
	logger.add(
		_errfile,
		colorize=False,
		compression="gz",
		format="<green>{time:%Y-%m-%d %H:%M:%S%z}></green> <level>{level:8s} {name}:{function}:{line:03d}  {message}</level>",
		rotation="10 MB",
		level="ERROR",
	)
	# logger.add("debug.log", rotation="10 MB", level="DEBUG")
	# logger.add("info.log", rotation="10 MB", level="INFO")
	# logger.add("warning.log", rotation="10 MB", level="WARNING")
	# logger.add("critical.log", rotation="10 MB", level="CRITICAL")

	# Database
	_db_url = env("SQLALCHEMY_DATABASE_URI")
	_db_schema = env("DB_SCHEMA")
	engine = create_engine(_db_url, echo=_debug)

	@sa.event.listens_for(engine, "connect", insert=True)
	def set_search_path(dbapi_connection, connection_record):
		"""
		Set schema search path in database
		"""
		sql = f"SET SESSION search_path TO {_db_schema},public;"
		existing_autocommit = dbapi_connection.autocommit
		dbapi_connection.autocommit = True
		cursor = dbapi_connection.cursor()
		cursor.execute(sql)
		cursor.close()
		dbapi_connection.autocommit = existing_autocommit

	init()
	retries = 3
	while retries > 0:
		try:
			# main()
			get_prices()
			retries = -1
		except Exception as e:
			retries -= 1
			logger.exception("Exception: %s" % e)
			sleep(30)
